import streamlit as st
import numpy as np
import librosa
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import tensorflow as tf
from tensorflow.keras import layers, models
import io
import soundfile as sf
import base64

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë”¥í˜ì´í¬ ìŒì„± íƒì§€", layout="wide")

# í•©ì„± ì˜¤ë””ì˜¤ ìƒì„± í•¨ìˆ˜
def generate_synthetic_audio(is_real=True, duration=3, sr=22050):
    t = np.linspace(0, duration, int(sr * duration))
    if is_real:
        # ìì—°ìŠ¤ëŸ¬ìš´ ì£¼íŒŒìˆ˜ë¥¼ ê°€ì§„ ì§„ì§œ ìŒì„± ëª¨ì‚¬
        freq = 200 + 100 * np.sin(2 * np.pi * 0.1 * t)
        audio = 0.5 * np.sin(2 * np.pi * freq * t)
    else:
        # ì¸ìœ„ì  íŒ¨í„´ê³¼ ë…¸ì´ì¦ˆë¥¼ ë”í•œ ë”¥í˜ì´í¬ ìŒì„± ëª¨ì‚¬
        freq = 200 + 50 * np.sin(2 * np.pi * 0.2 * t)
        audio = 0.5 * np.sin(2 * np.pi * freq * t) + 0.1 * np.random.randn(len(t))
    return audio, sr

# MFCC íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜
def extract_mfcc(audio, sr, n_mfcc=13):
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)
    return np.mean(mfcc.T, axis=0)

# ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ ì¶”ì¶œ í•¨ìˆ˜
def extract_spectrogram(audio, sr, n_mels=128, hop_length=512):
    S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, hop_length=hop_length)
    S_dB = librosa.power_to_db(S, ref=np.max)
    S_dB = S_dB[:, :128]
    if S_dB.shape[1] < 128:
        S_dB = np.pad(S_dB, ((0, 0), (0, 128 - S_dB.shape[1])), mode='constant')
    return S_dB

# ì˜¤ë””ì˜¤ ì¬ìƒ í”Œë ˆì´ì–´ ìƒì„± í•¨ìˆ˜
def get_audio_player(audio, sr):
    buffer = io.BytesIO()
    sf.write(buffer, audio, sr, format='WAV')
    audio_base64 = base64.b64encode(buffer.getvalue()).decode()
    audio_html = f'<audio controls><source src="data:audio/wav;base64,{audio_base64}" type="audio/wav"></audio>'
    return audio_html

# ê°„ë‹¨í•œ CNN ëª¨ë¸ êµ¬ì„±
def build_cnn_model(input_shape=(128, 128, 1)):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# ë”¥í˜ì´í¬ ìŒì„± íƒì§€ ì•± ì‹¤í–‰ í•¨ìˆ˜
def run():
    # íŠœí† ë¦¬ì–¼ ì„¤ëª…
    st.title("ğŸ™ï¸ ë”¥í˜ì´í¬ ìŒì„± íƒì§€ ì›¹ì•±")
    st.header("íŠœí† ë¦¬ì–¼: ë”¥í˜ì´í¬ ìŒì„± íƒì§€ ì´í•´í•˜ê¸°")
    st.markdown("""
    ì´ ì›¹ì•±ì€ ê³ ë“±í•™ìƒì„ ëŒ€ìƒìœ¼ë¡œ AIê°€ **ì§„ì§œ ìŒì„±**ê³¼ **ë”¥í˜ì´í¬ ìŒì„±**ì„ ì–´ë–»ê²Œ êµ¬ë³„í•˜ëŠ”ì§€ í•™ìŠµí•˜ë„ë¡ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ íŠœí† ë¦¬ì–¼ì„ ë”°ë¼ë³´ì„¸ìš”:
    
    ### ë”¥í˜ì´í¬ ìŒì„±ì´ë€?
    - **ì§„ì§œ ìŒì„±**: ìœ íŠœë¸Œ ì¸í„°ë·°, íŒŸìºìŠ¤íŠ¸, ë‰´ìŠ¤ ë“±ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ìŒëœ ì‚¬ëŒì˜ ëª©ì†Œë¦¬ì…ë‹ˆë‹¤.
    - **ë”¥í˜ì´í¬ ìŒì„±**: AIê°€ ì‚¬ëŒì˜ ëª©ì†Œë¦¬ë¥¼ ëª¨ë°©í•´ ë§Œë“¤ì–´ë‚¸ ìŒì„±ì…ë‹ˆë‹¤.
    - **ì™œ ì¤‘ìš”í• ê¹Œìš”?**: ë”¥í˜ì´í¬ëŠ” ê°€ì§œ ë‰´ìŠ¤ë‚˜ í—ˆìœ„ ì •ë³´ë¥¼ í¼ëœ¨ë¦´ ë•Œ ì´ìš©ë  ìˆ˜ ìˆì–´ ìœ„í—˜í•©ë‹ˆë‹¤. ì´ ì•±ì€ AIê°€ ì–´ë–»ê²Œ ì´ë¥¼ íƒì§€í•  ìˆ˜ ìˆëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.
    
    ### ì•± ë™ì‘ ì›ë¦¬
    1. **ì˜¤ë””ì˜¤ ìƒì„± ë˜ëŠ” ì—…ë¡œë“œ**  
       - ì˜ˆì‹œ 'ì§„ì§œ' ë˜ëŠ” 'ê°€ì§œ' ìŒì„± ìƒì„± ë²„íŠ¼ í´ë¦­  
       - ë˜ëŠ” ì§ì ‘ WAV íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥  
    2. **ì˜¤ë””ì˜¤ ë¶„ì„**  
       - ìŒì„±ì—ì„œ **MFCC** (ìŒì„± íŠ¹ì§•)ì™€ **ìŠ¤í™íŠ¸ë¡œê·¸ë¨** (ì‹œê°ì  ì£¼íŒŒìˆ˜ íŒ¨í„´) ì¶”ì¶œ  
    3. **AI ëª¨ë¸ í•™ìŠµ**  
       - **ëœë¤ í¬ë ˆìŠ¤íŠ¸**: MFCC íŠ¹ì§• ê¸°ë°˜ ë¶„ë¥˜  
       - **CNN (í•©ì„±ê³± ì‹ ê²½ë§)**: ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ ë¶„ì„  
    4. **ìŒì„± ë¶„ë¥˜**  
       - AIê°€ ìŒì„±ì˜ ì§„ìœ„(ì§„ì§œ/ê°€ì§œ) ë° í™•ë¥ ì„ ì˜ˆì¸¡í•´ ì¶œë ¥  
    5. **ìœ¤ë¦¬ì  ì‚¬ê³ **  
       - ë”¥í˜ì´í¬ ê¸°ìˆ ì˜ ì˜¤ìš©ê³¼ íƒì§€ì˜ ì‚¬íšŒì  ì˜ë¯¸ë¥¼ í† ë¡ í•˜ì„¸ìš”.
    
    ### ì‚¬ìš© ë°©ë²•
    - ìŒì„±ì„ ìƒì„±í•˜ê±°ë‚˜ ì—…ë¡œë“œí•˜ì„¸ìš”.  
    - ì²­ì·¨í•˜ê³  ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì„ í™•ì¸í•˜ì„¸ìš”.  
    - **[í•™ìŠµ í›„ ë¶„ë¥˜]** ë²„íŠ¼ì„ ëˆ„ë¥´ê³  AI ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ì„¸ìš”.  
    - í† ë¡  ì§ˆë¬¸ì„ í†µí•´ AI ìœ¤ë¦¬ì™€ ì±…ì„ì— ëŒ€í•´ í•¨ê»˜ ìƒê°í•´ë³´ì„¸ìš”.
    
    ### ì°¸ê³ 
    ì‹¤ì œ ë”¥í˜ì´í¬ íƒì§€ì—ëŠ” **LSTM, Transformer** ê°™ì€ ë³µì¡í•œ ëª¨ë¸ê³¼ ëŒ€ìš©ëŸ‰ ë°ì´í„°ê°€ ì‚¬ìš©ë˜ì§€ë§Œ, ì´ ì•±ì—ì„œëŠ” í•™ìƒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ **ëœë¤ í¬ë ˆìŠ¤íŠ¸**ì™€ **CNN**ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
    """)

    # ë©”ì¸ ì•± UI
    st.header("ë”¥í˜ì´í¬ ìŒì„± íƒì§€ ì‹œìŠ¤í…œ")

    # 1ë‹¨ê³„: ìŒì„± ìƒì„± ë˜ëŠ” ì—…ë¡œë“œ
    st.subheader("1ë‹¨ê³„: ìŒì„± ìƒì„± ë˜ëŠ” ì—…ë¡œë“œ")
    col1, col2 = st.columns(2)

    with col1:
        if st.button("ì§„ì§œ ìŒì„± ìƒì„±"):
            audio, sr = generate_synthetic_audio(is_real=True)
            st.session_state['audio'] = audio
            st.session_state['sr'] = sr
            st.session_state['is_real'] = True
            st.markdown("**âœ”ï¸ ì§„ì§œ ìŒì„± ìƒ˜í”Œ ìƒì„±ë¨**")
            st.markdown(get_audio_player(audio, sr), unsafe_allow_html=True)

    with col2:
        if st.button("ê°€ì§œ ìŒì„± ìƒì„±"):
            audio, sr = generate_synthetic_audio(is_real=False)
            st.session_state['audio'] = audio
            st.session_state['sr'] = sr
            st.session_state['is_real'] = False
            st.markdown("**âœ”ï¸ ê°€ì§œ ìŒì„± ìƒ˜í”Œ ìƒì„±ë¨**")
            st.markdown(get_audio_player(audio, sr), unsafe_allow_html=True)

    uploaded_file = st.file_uploader("ë˜ëŠ” WAV íŒŒì¼ ì—…ë¡œë“œ", type=["wav"])
    if uploaded_file:
        audio, sr = librosa.load(uploaded_file, sr=22050)
        st.session_state['audio'] = audio
        st.session_state['sr'] = sr
        st.session_state['is_real'] = None
        st.markdown("**âœ”ï¸ ì—…ë¡œë“œëœ ìŒì„±**")
        st.markdown(get_audio_player(audio, sr), unsafe_allow_html=True)

    # 2ë‹¨ê³„: ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì‹œê°í™”
    if 'audio' in st.session_state:
        st.subheader("2ë‹¨ê³„: ìŠ¤í™íŠ¸ë¡œê·¸ë¨ í™•ì¸")
        fig, ax = plt.subplots()
        S = librosa.feature.melspectrogram(y=st.session_state['audio'], sr=st.session_state['sr'])
        S_dB = librosa.power_to_db(S, ref=np.max)
        librosa.display.specshow(S_dB, sr=st.session_state['sr'], x_axis='time', y_axis='mel', ax=ax)
        ax.set(title='Mel ìŠ¤í™íŠ¸ë¡œê·¸ë¨')
        st.pyplot(fig)

    # 3ë‹¨ê³„: AI í•™ìŠµ ë° ë¶„ë¥˜
    st.subheader("3ë‹¨ê³„: AIë¡œ ë¶„ë¥˜í•˜ê¸°")
    if st.button("í•™ìŠµ í›„ ë¶„ë¥˜ ì‹¤í–‰"):
        # ëœë¤ í¬ë ˆìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
        X_rf, y_rf = [], []
        for _ in range(50):
            ra, sr = generate_synthetic_audio(is_real=True)
            fa, _ = generate_synthetic_audio(is_real=False)
            X_rf.append
